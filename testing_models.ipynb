{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Phase: Testing our created models\n",
    "\n",
    "Now that we have created quite a few models it's useful now to see how they can compare to each other. We used the evaluation dataset not to train the model, but to instead validate the development process. It's not a good idea to evaluate different models ones against each other with the same evaluation dataset, this because the validation set was not used directly for training, but has influenced the model, in a way \"seeing\" the data.\n",
    "\n",
    "By using a separate test data that has not been used at all during training we could get a better estimate on how different models will behave in the real world, on data never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.8 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import albumentations as A\n",
    "\n",
    "from utils import get_evals, set_cuda_and_seed, load_checkpoint\n",
    "from model import UNET\n",
    "from dataset import SN6Dataset\n",
    "\n",
    "import warnings\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning) # Masks are not georeferences, so we can ignore this warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # This will throw a warning message about cudnn, this is normal (https://github.com/pytorch/pytorch/pull/125790)\n",
    "\n",
    "\n",
    "MEAN = [0, 0, 0]\n",
    "STD = [1.0, 1.0, 1.0]\n",
    "NUM_WORKERS = 4\n",
    "VAL_BATCH_SIZE = 2\n",
    "\n",
    "DATASET_PATH = \"data/train/AOI_11_Rotterdam/\"\n",
    "OUTPUT_PATH = \"output/\"\n",
    "DATA_PATH = OUTPUT_PATH + \"data/\"\n",
    "CHECKPOINT_PATH = OUTPUT_PATH + \"checkpoints/\"\n",
    "GRAPH_PATH = OUTPUT_PATH + \"graphs/\"\n",
    "TEST_PATH = OUTPUT_PATH + \"test/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.3.0+cu121  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = set_cuda_and_seed()\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1.0),\n",
    "    A.Resize(320, 320)\n",
    "])\n",
    "\n",
    "test_dataset = SN6Dataset(DATASET_PATH, \"test\", transform=test_transforms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a function that iterates on the models inside  checkpoints. Once we loaded each one we'll be calculating the evaluations on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpoint.pth', 'checkpoint_2.pth', 'best_6 - LR1e-4 TrainBatch8 Epoch80 Resize - NoAugmentation.pth', 'best_5 - LR1e-4 TrainBatch8 Epoch100 Resize.pth', 'checkpoint_5 - LR1e-4 TrainBatch8 Epoch100 Resize.pth', 'checkpoint_5 - LR1e-4 TrainBatch8 Epoch24 Resize.pth', 'best_69 - LR1e-3 TrainBatch8 Epoch24 noScheduler.pth', 'checkpoint_2 - LR1e-3 TrainBatch8 Epoch24 noScheduler.pth', 'best_4 - LR1e-4 TrainBatch8 Epoch24.pth', 'best.pth', 'best_2 - LR1e-3 TrainBatch8 Epoch24 noScheduler.pth', 'best_5 - LR1e-4 TrainBatch8 Epoch24 Resize.pth', 'best_3 - LR1e-3 TrainBatch8 Epoch24.pth', 'checkpoint_4 - LR1e-4 TrainBatch8 Epoch24.pth', 'checkpoint_6 - LR1e-4 TrainBatch8 Epoch80 Resize - NoAugmentation.pth', 'best_2.pth', 'checkpoint_3 - LR1e-3 TrainBatch8 Epoch24.pth', 'checkpoint_69 - LR1e-3 TrainBatch8 Epoch24 noScheduler.pth']\n",
      "found best checkpoint best_6 - LR1e-4 TrainBatch8 Epoch80 Resize - NoAugmentation.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best_6 - LR1e-4 TrainBatch8 Epoch80 Resize - NoAugmentation\n",
      "Test_loss23.326334027519003, Precision: 0.12047188729047775, Recall: 0.5661718249320984, F1: 0.19867008924484253, Accuracy: 0.6586465835571289 \n",
      "found best checkpoint best_5 - LR1e-4 TrainBatch8 Epoch100 Resize.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best_5 - LR1e-4 TrainBatch8 Epoch100 Resize\n",
      "Test_loss26.492963424900122, Precision: 0.10938426107168198, Recall: 0.06179557740688324, F1: 0.07897499203681946, Accuracy: 0.8922750353813171 \n",
      "found best checkpoint best_69 - LR1e-3 TrainBatch8 Epoch24 noScheduler.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best_69 - LR1e-3 TrainBatch8 Epoch24 noScheduler\n",
      "Test_loss1.6084879246807238, Precision: 0.20999042689800262, Recall: 0.03880922496318817, F1: 0.0655110701918602, Accuracy: 0.917249321937561 \n",
      "found best checkpoint best_4 - LR1e-4 TrainBatch8 Epoch24.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best_4 - LR1e-4 TrainBatch8 Epoch24\n",
      "Test_loss8.932827625358314, Precision: 0.01784595660865307, Recall: 0.01477028988301754, F1: 0.01616310328245163, Accuracy: 0.8656107783317566 \n",
      "found best checkpoint best.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best\n",
      "Test_loss88.889378486321, Precision: 0.10752838850021362, Recall: 0.995975911617279, F1: 0.19410106539726257, Accuracy: 0.38187161087989807 \n",
      "found best checkpoint best_2 - LR1e-3 TrainBatch8 Epoch24 noScheduler.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best_2 - LR1e-3 TrainBatch8 Epoch24 noScheduler\n",
      "Test_loss10.8698386856687, Precision: 0.02732749655842781, Recall: 0.0031458758749067783, F1: 0.005642229691147804, Accuracy: 0.9171274900436401 \n",
      "found best checkpoint best_5 - LR1e-4 TrainBatch8 Epoch24 Resize.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best_5 - LR1e-4 TrainBatch8 Epoch24 Resize\n",
      "Test_loss25.24054085092935, Precision: 0.41390305757522583, Recall: 0.00024868128821253777, F1: 0.0004970639711245894, Accuracy: 0.9252532720565796 \n",
      "found best checkpoint best_3 - LR1e-3 TrainBatch8 Epoch24.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best_3 - LR1e-3 TrainBatch8 Epoch24\n",
      "Test_loss20.174026711642394, Precision: 0.0, Recall: 0.0, F1: 0.0, Accuracy: 0.7657801508903503 \n",
      "found best checkpoint best_2.pth\n",
      "loading checkpoint\n",
      "Saving predictions to: output/test/best_2\n",
      "Test_loss3.5929401584884575, Precision: 0.2722695469856262, Recall: 0.03238566219806671, F1: 0.05788596346974373, Accuracy: 0.9212119579315186 \n"
     ]
    }
   ],
   "source": [
    "model = UNET(in_channels=3, out_channels=1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(os.listdir(CHECKPOINT_PATH))\n",
    "for checkpoint in os.listdir(CHECKPOINT_PATH):\n",
    "    if checkpoint.startswith(\"best\") and checkpoint.endswith(\".pth\"):\n",
    "        print(\"found best checkpoint\", checkpoint)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=VAL_BATCH_SIZE, pin_memory=True, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        load_checkpoint(CHECKPOINT_PATH + checkpoint, model, optimizer, criterion)\n",
    "        checkpoint_name = checkpoint.split(\".\")[0]\n",
    "        folder_path = os.path.join(TEST_PATH, checkpoint_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        test_loss, precision, recall, f1, accuracy = get_evals(test_loader, model, criterion,  device, True, folder_path)\n",
    "        print(f\"Test_loss{test_loss}, Precision: {precision}, Recall: {recall}, F1: {f1}, Accuracy: {accuracy} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
