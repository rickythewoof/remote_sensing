{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Notebook for remote sensing work\n",
    "Repository made for Artificial Intelligence & Neural Network course with Prof. Ciarfuglia @ Sapienza \n",
    "\n",
    "Import necessary items with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import our own modules\n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "import torch.utils.data as data\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning) # Masks are not georeferences, so we can ignore this warning\n",
    "\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should test that the CUDA platform has been successfully recognized and it's being in use with pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.3.0+cu121  Device: cuda\n",
      "PyTorch version:  2.3.0+cu121\n",
      "CUDA version:  12.1\n",
      "cuDNN version:  8902\n"
     ]
    }
   ],
   "source": [
    "device = utils.set_cuda_and_seed()\n",
    "\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA version: \", torch.version.cuda)\n",
    "print(\"cuDNN version: \", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some parameters, used for hyperparameter tuning later\n",
    "\n",
    "Here we'll setup some parameters, that will be used for hyperparameter tuning once we have a PoC that actually works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEAN = [63.02235933, 66.64201154, 60.63862196]\n",
    "# STD = [55.50368184, 55.35826425, 52.63471437]\n",
    "MEAN = [0, 0, 0]\n",
    "STD = [1.0, 1.0, 1.0]\n",
    "INITIAL_LR = 0.001\n",
    "MAX_LR = 0.01\n",
    "SIZE = 256\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 16\n",
    "LOAD_CHECKPOINT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    " - dataset analysis\n",
    " - mean and standard deviation calculatiom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "Before starting, we need to do some preliminary analysis on our dataset.\n",
    "Inside split_dataset.py we already split our images into 3 different categories.\n",
    "We'll be using:\n",
    " - train.txt as a training dataset\n",
    " - val.txt to validate that our model correctly predicts masks\n",
    " - test.txt to challenge different models one against the other\n",
    "\n",
    "We should also calculate mean and std values of our train dataset, and we'll apply them to all of our sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' mean, std = utils.get_mean_std(path_to_train_data=\"data/train/AOI_11_Rotterdam/splits/train.txt\")\\nprint(\"Mean: \", mean)\\nprint(\"Std: \", std) \\n '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" mean, std = utils.get_mean_std(path_to_train_data=\"data/train/AOI_11_Rotterdam/splits/train.txt\")\n",
    "print(\"Mean: \", mean)\n",
    "print(\"Std: \", std) \n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset class\n",
    "\n",
    "Now we'll need to create a SN6Dataset derived from data.Dataset that will import the data and return the data and labels, and that implements __len__ and __getitem__ methods\n",
    "We'll be using RasterIO\n",
    "\n",
    "We can see the implementation of the dataset in src/dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=255.0),\n",
    "    A.Resize(SIZE, SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5)\n",
    "])\n",
    "\n",
    "eval_transforms = A.Compose([\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=255.0),\n",
    "    A.Resize(SIZE, SIZE)\n",
    "])\n",
    "\n",
    "from dataset import SN6Dataset\n",
    "\n",
    "train_dataset = SN6Dataset('./data/train/AOI_11_Rotterdam', transform=train_transforms, split='train')\n",
    "eval_dataset = SN6Dataset('./data/train/AOI_11_Rotterdam', transform=eval_transforms, split='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DataLoader\n",
    "\n",
    "We'll now import the dataset into a dataloader, and just to see that everything's working we'll show the first image of the batch\n",
    "\n",
    "Since we have normalized the images the image won't be shown correctly. That's normal, since now the values are centered in zero\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([16, 3, 256, 256]), Mask shape: torch.Size([16, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=NUM_WORKERS)\n",
    "eval_loader = data.DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=True,  pin_memory=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "image, mask = next(iter(train_loader))\n",
    "print(f\"Image shape: {image.shape}, Mask shape: {mask.shape}\")\n",
    "# utils.visualize_image(image[0], mask[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the training model\n",
    "\n",
    "We'll be using UNET, a convolutional neural network (CNN), for our task.\n",
    "\n",
    "UNET is a popular architecture for image segmentation tasks. It is widely used in various domains, including medical imaging, remote sensing, and computer vision.\n",
    "\n",
    "NOTE: This will throw a warning message about cudnn, this is normal and documented [HERE](https://github.com/pytorch/pytorch/pull/125790)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1827: 100%|██████████| 170/170 [01:06<00:00,  2.56it/s]\n",
      "/home/ricky/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:952: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv_transpose2d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1349.7325\n",
      "Dice Score: 0.1136\n",
      "Epoch 2 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1261: 100%|██████████| 170/170 [01:04<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1475.0793\n",
      "Dice Score: 0.0082\n",
      "Epoch 3 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1526: 100%|██████████| 170/170 [01:05<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1428.2552\n",
      "Dice Score: 0.0853\n",
      "Epoch 4 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1431: 100%|██████████| 170/170 [01:03<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1460.6746\n",
      "Dice Score: 0.0460\n",
      "Epoch 5 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1470: 100%|██████████| 170/170 [01:05<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1425.7925\n",
      "Dice Score: 0.0741\n",
      "Epoch 6 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0942: 100%|██████████| 170/170 [01:05<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1413.0586\n",
      "Dice Score: 0.0978\n",
      "Epoch 7 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0977: 100%|██████████| 170/170 [01:05<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1430.3217\n",
      "Dice Score: 0.0792\n",
      "Epoch 8 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1545: 100%|██████████| 170/170 [01:05<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1421.3517\n",
      "Dice Score: 0.0964\n",
      "Epoch 9 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1113: 100%|██████████| 170/170 [01:14<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1437.5959\n",
      "Dice Score: 0.0793\n",
      "Epoch 10 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1719: 100%|██████████| 170/170 [01:34<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1419.4114\n",
      "Dice Score: 0.0979\n",
      "Epoch 11 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0832: 100%|██████████| 170/170 [01:05<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1425.7906\n",
      "Dice Score: 0.0978\n",
      "Epoch 12 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0823: 100%|██████████| 170/170 [01:04<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1422.1395\n",
      "Dice Score: 0.0989\n",
      "Epoch 13 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0562: 100%|██████████| 170/170 [01:05<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1416.0118\n",
      "Dice Score: 0.1075\n",
      "Epoch 14 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0860: 100%|██████████| 170/170 [01:05<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1414.8850\n",
      "Dice Score: 0.1049\n",
      "Epoch 15 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0679: 100%|██████████| 170/170 [01:03<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1413.6678\n",
      "Dice Score: 0.1122\n",
      "Epoch 16 of 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1134: 100%|██████████| 170/170 [01:05<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1411.0724\n",
      "Dice Score: 0.1077\n"
     ]
    }
   ],
   "source": [
    "from model import UNET\n",
    "from train import train\n",
    "\n",
    "model = UNET(in_channels = 3, out_channels = 1).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=INITIAL_LR)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=MAX_LR, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "if LOAD_CHECKPOINT:\n",
    "    checkpoint = torch.load(\"checkpoints/checkpoint_16.pth\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "\n",
    "# Training model\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1} of {EPOCHS}\")\n",
    "    train(train_loader, model, optimizer, criterion, scaler, scheduler, device)\n",
    "    # Save model\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict()\n",
    "    }\n",
    "    utils.save_checkpoint(checkpoint, filename=f\"checkpoints/checkpoint_{epoch+1}.pth\")\n",
    "    utils.get_evals(eval_loader, model, device)\n",
    "    utils.save_predictions_as_image(eval_loader, model, device, \"data/eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "https://www.nature.com/articles/s41598-024-56706-x \n",
    "https://medium.com/@nghihuynh_37300/understanding-evaluation-metrics-in-medical-image-segmentation-d289a373a3f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
