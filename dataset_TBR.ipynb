{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Notebook for remote sensing work\n",
    "Repository made for Artificial Intelligence & Neural Network course with Prof. Ciarfuglia @ Sapienza \n",
    "\n",
    "Import necessary items with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import our own modules\n",
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "import utils\n",
    "import dataset\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "import torch.utils.data as data\n",
    "from rasterio.errors import NotGeoreferencedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=NotGeoreferencedWarning)\n",
    "\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should test that the CUDA platform has been successfully recognized and it's being in use with pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = utils.set_cuda_and_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    " - dataset analysis\n",
    " - mean and standard deviation calculatiom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "Before starting, we need to do some preliminary analysis on our dataset.\n",
    "Inside split_dataset.py we already split our images into 3 different categories.\n",
    "We'll be using:\n",
    " - train.txt as a training dataset\n",
    " - val.txt to validate that our model correctly predicts masks\n",
    " - test.txt to challenge different models one against the other\n",
    "\n",
    "We should also calculate mean and std values of our train dataset, and we'll apply them to all of our sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, std = utils.get_mean_std(path_to_train_data=\"data/train/AOI_11_Rotterdam/splits/train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset class\n",
    "\n",
    "Now we'll need to create a SN6Dataset derived from data.Dataset that will import the data and return the data and labels, and that implements __len__ and __getitem__ methods\n",
    "We'll be using RasterIO\n",
    "\n",
    "We can see the implementation of the dataset in src/dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Normalize(mean=[63.02, 66.64, 60.64], std=[55.5,55.35,52.63]),\n",
    "    A.Resize(128, 128)\n",
    "])\n",
    "\n",
    "train_dataset = dataset.SN6Dataset('./data/train/AOI_11_Rotterdam', transform=transforms, split='train')\n",
    "eval_dataset = dataset.SN6Dataset('./data/train/AOI_11_Rotterdam', transform=transforms, split='val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use DataLoader\n",
    "\n",
    "We'll now import the dataset into a dataloader, and just to see that everything's working we'll show the first image of the batch\n",
    "\n",
    "Since we have normalized the images the image won't be shown correctly. That's normal, since now the values are centered in zero\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "eval_loader = data.DataLoader(eval_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "image, mask = next(iter(data_loader))\n",
    "print(image[0].shape, mask[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the training model\n",
    "\n",
    "We'll be using UNET, a convolutional neural network (CNN), for our task.\n",
    "\n",
    "UNET is a popular architecture for image segmentation tasks. It is widely used in various domains, including medical imaging, remote sensing, and computer vision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3261:   8%|▊         | 14/170 [00:10<02:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([16, 128, 128])\n",
      "Output type:  torch.float32\n",
      "Mask shape:  torch.Size([16, 128, 128])\n",
      "Mask type:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2652:   9%|▉         | 15/170 [00:11<02:11,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([16, 128, 128])\n",
      "Output type:  torch.float32\n",
      "Mask shape:  torch.Size([16, 128, 128])\n",
      "Mask type:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2526:   9%|▉         | 16/170 [00:12<02:20,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([16, 128, 128])\n",
      "Output type:  torch.float32\n",
      "Mask shape:  torch.Size([16, 128, 128])\n",
      "Mask type:  torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1736:  10%|█         | 17/170 [00:13<02:21,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:  torch.Size([16, 128, 128])\n",
      "Output type:  torch.float32\n",
      "Mask shape:  torch.Size([16, 128, 128])\n",
      "Mask type:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "from model import UNET\n",
    "from train import train\n",
    "\n",
    "model = UNET(in_channels = 3, out_channels = 1).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=optimizer.param_groups[0]['lr']*0.9)\n",
    "\n",
    "train(data_loader, eval_loader, model, optimizer, criterion, scheduler, device, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
